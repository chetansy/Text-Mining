{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da7f1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [\"This was awesome an awesome movie\",\n",
    "          \"Greate movie! I liked It a lot\",\n",
    "          \"Happy Ending! awsome acting by the Hero !\",\n",
    "          \"Loved It ! truely great\",\n",
    "          \"bad not upto mark\",\n",
    "          \"could have been better\",\n",
    "          \"surely a disaapointing movie\"]\n",
    "\n",
    "y_train = [1,1,1,1,0,0,0]  ## 1-Positive, 0 - Negative\n",
    "\n",
    "x_test = [\"I Was happy & happy and i Loved the acting in the movie\",\n",
    "         \"the movie i saw was bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c529a5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This was awesome an awesome movie',\n",
       " 'Greate movie! I liked It a lot',\n",
       " 'Happy Ending! awsome acting by the Hero !',\n",
       " 'Loved It ! truely great',\n",
       " 'bad not upto mark',\n",
       " 'could have been better',\n",
       " 'surely a disaapointing movie']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f77cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Chetan\n",
      "[nltk_data]     Yewale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Cleaning\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feac7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "358fbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcleanedText(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    new_tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    \n",
    "    stemmed_tokens = [ps.stem(tokens) for tokens in new_tokens]\n",
    "    \n",
    "    clean_text = \" \".join(stemmed_tokens)\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9828c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clean = [getcleanedText(i) for i in x_train]\n",
    "xt_clean = [getcleanedText(i) for i in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2196f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesom awesom movi',\n",
       " 'great movi like lot',\n",
       " 'happi end awsom act hero',\n",
       " 'love trueli great',\n",
       " 'bad upto mark',\n",
       " 'could better',\n",
       " 'sure disaapoint movi']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fd0270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vectorize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34b5d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c832876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db5767b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vect = cv.fit_transform(x_clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cc4ddef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3fc10b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act', 'act hero', 'awesom', 'awesom awesom', 'awesom movi', 'awsom', 'awsom act', 'bad', 'bad upto', 'better', 'could', 'could better', 'disaapoint', 'disaapoint movi', 'end', 'end awsom', 'great', 'great movi', 'happi', 'happi end', 'hero', 'like', 'like lot', 'lot', 'love', 'love trueli', 'mark', 'movi', 'movi like', 'sure', 'sure disaapoint', 'trueli', 'trueli great', 'upto', 'upto mark']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "231dcf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_vect = cv.transform(xt_clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce1a7391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0de2717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### multinomial Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12d4defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a17edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba1c295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn .fit(x_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe73b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mn.predict(xt_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2ff2de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66ee7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
